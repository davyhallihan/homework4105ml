{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDetCOGFvKzPwxKsEWM714"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "M8xi_SPH2Wkt"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sH87PX8e0_qP"
      },
      "outputs": [],
      "source": [
        "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "t_c = torch.tensor(t_c)\n",
        "t_u = torch.tensor(t_u)\n",
        "\n",
        "def model(t_u, w1, w2, b):\n",
        "  return w2 * t_u ** 2 + w1 * t_u + b;\n",
        "\n",
        "def mseloss(t_p, t_c):\n",
        "  squared_diffs = (t_p - t_c) ** 2\n",
        "  return squared_diffs.mean();"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def trainingloop (epochs, lr, params, t_u, t_c):\n",
        "  optimizer = optim.SGD([params], lr=lr)\n",
        "  #optimizer = optim.Adam([params], lr=lr)\n",
        "\n",
        "  t_p = model(t_u, *params)\n",
        "  print('Starting Loss %d' % (mseloss(t_p, t_c)))\n",
        "\n",
        "  for epoch in range(1, epochs+1):\n",
        "    if params.grad is not None:\n",
        "      params.grad.zero_()\n",
        "\n",
        "    t_p = model(t_u, *params)\n",
        "    loss = mseloss(t_p, t_c)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      params -= lr * params.grad\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "\n",
        "trainingloop(\n",
        "    epochs = 5000, #100000\n",
        "    lr = 0.000000042, #  lr = 0.0000000085, # lr = 0.0000000042, # lr = 0.00000000042, # lr = 0.0000000-42,\n",
        "    params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True),\n",
        "    t_u = t_u,\n",
        "    t_c = t_c\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM-Da-jE1okY",
        "outputId": "a72c2ec7-5182-4d2c-e1bf-de46caddba93"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Loss 11709471\n",
            "Epoch 500, Loss 199.108978\n",
            "Epoch 1000, Loss 194.201599\n",
            "Epoch 1500, Loss 189.417542\n",
            "Epoch 2000, Loss 184.753677\n",
            "Epoch 2500, Loss 180.206985\n",
            "Epoch 3000, Loss 175.774475\n",
            "Epoch 3500, Loss 171.453278\n",
            "Epoch 4000, Loss 167.240631\n",
            "Epoch 4500, Loss 163.134537\n",
            "Epoch 5000, Loss 159.131485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Read Dataset\n",
        "hsdb = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/4105a4/Housing.csv')\n",
        "cndb = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/4105a4/cancer.csv')\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "nmlz = StandardScaler()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsnsifS0NYCE",
        "outputId": "adf56ec0-e2c7-48ed-8e07-7d2e02b90990"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Problem 2\n",
        "df_train, df_test = train_test_split(hsdb, train_size = 0.8, test_size = 0.2, random_state = 100)\n",
        "\n",
        "def binary_map(x):\n",
        "    return x.map({'yes': 1, 'no': 0})\n",
        "\n",
        "def trinary_map(x):\n",
        "    return x.map({'unfurnished': 0, 'semi-furnished': 0.5, 'furnished' : 1})\n",
        "\n",
        "binarymap =  ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
        "trinarymap = ['furnishingstatus']\n",
        "\n",
        "df_train[binarymap] = df_train[binarymap].apply(binary_map)\n",
        "df_test[binarymap] = df_test[binarymap].apply(binary_map)\n",
        "\n",
        "df_train[trinarymap] = df_train[trinarymap].apply(trinary_map)\n",
        "df_test[trinarymap] = df_test[trinarymap].apply(trinary_map)\n",
        "\n",
        "truth_train = df_train.values[:, 0]\n",
        "records_train = len(truth_train)\n",
        "bias_train = np.ones((records_train, 1))\n",
        "\n",
        "truth_val = df_test.values[:, 0]\n",
        "records_val = len(truth_val)\n",
        "bias_val = np.ones((records_val, 1))\n",
        "\n",
        "num_vars = ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'parking', 'price']\n",
        "\n",
        "df_stdt = df_train\n",
        "Standard = StandardScaler()\n",
        "df_stdt[num_vars] = Standard.fit_transform(df_train[num_vars])\n",
        "\n",
        "df_stdv = df_test\n",
        "df_stdv[num_vars] = Standard.fit_transform(df_test[num_vars])\n",
        "\n",
        "area_train = df_stdt.values[:, 1].reshape(records_train, 1)\n",
        "beds_train = df_stdt.values[:, 2].reshape(records_train, 1)\n",
        "baths_train = df_stdt.values[:, 3].reshape(records_train, 1)\n",
        "stories_train = df_stdt.values[:, 4].reshape(records_train, 1)\n",
        "parking_train = df_stdt.values[:, 10].reshape(records_train, 1)\n",
        "mainrd_train = df_stdt.values[:, 5].reshape(records_train, 1)\n",
        "guest_train = df_stdt.values[:, 6].reshape(records_train, 1)\n",
        "basement_train = df_stdt.values[:, 7].reshape(records_train, 1)\n",
        "hotwater_train = df_stdt.values[:, 8].reshape(records_train, 1)\n",
        "hvac_train = df_stdt.values[:, 9].reshape(records_train, 1)\n",
        "prefarea_train = df_stdt.values[:, 11].reshape(records_train, 1)\n",
        "\n",
        "area_val = df_stdv.values[:, 1].reshape(records_val, 1)\n",
        "beds_val = df_stdv.values[:, 2].reshape(records_val, 1)\n",
        "baths_val = df_stdv.values[:, 3].reshape(records_val, 1)\n",
        "stories_val = df_stdv.values[:, 4].reshape(records_val, 1)\n",
        "parking_val = df_stdv.values[:, 10].reshape(records_val, 1)\n",
        "mainrd_val = df_stdv.values[:, 5].reshape(records_val, 1)\n",
        "guest_val = df_stdv.values[:, 6].reshape(records_val, 1)\n",
        "basement_val = df_stdv.values[:, 7].reshape(records_val, 1)\n",
        "hotwater_val = df_stdv.values[:, 8].reshape(records_val, 1)\n",
        "hvac_val = df_stdv.values[:, 9].reshape(records_val, 1)\n",
        "prefarea_val = df_stdv.values[:, 11].reshape(records_val, 1)\n",
        "\n",
        "fulltrainexplanatory = torch.tensor(np.hstack((bias_train, area_train, beds_train, baths_train, stories_train, parking_train, mainrd_train, guest_train, basement_train, hotwater_train, hvac_train, prefarea_train)))\n",
        "fulltestexplanatory = torch.tensor(np.hstack((bias_val, area_val, beds_val, baths_val, stories_val, parking_val, mainrd_val, guest_val, basement_val, hotwater_val, hvac_val, prefarea_val)))\n",
        "\n",
        "partialtrainexplanatory = torch.tensor(np.hstack((bias_train, area_train, beds_train, baths_train, stories_train, parking_train)))\n",
        "partialtestexplanatory = torch.tensor(np.hstack((bias_val, area_val, beds_val, baths_val, stories_val, parking_val)))\n",
        "\n",
        "traintruth = torch.tensor(truth_train)\n",
        "testtruth = torch.tensor(truth_val)\n",
        "\n",
        "fulltrainexplanatory = fulltrainexplanatory.t()\n",
        "fulltestexplanatory = fulltestexplanatory.t()\n",
        "partialtrainexplanatory = partialtrainexplanatory.t()\n",
        "partialtestexplanatory = partialtestexplanatory.t()\n",
        "\n",
        "traintruth = traintruth.t()\n",
        "testtruth = testtruth.t()\n"
      ],
      "metadata": {
        "id": "gP3vgW4RNpH8"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def partialmodel(t_u, b, x1, x2, x3, x4, x5):\n",
        "  return b + x1*t_u + x2*t_u + x3*t_u + x4*t_u + x5*t_u;\n",
        "\n",
        "def fullmodel(t_u, b, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11):\n",
        "  return b + x1*t_u + x2*t_u + x3*t_u + x4*t_u + x5*t_u + x6*t_u + x7*t_u + x8*t_u + x9*t_u + x10*t_u + x11*t_u;\n",
        "\n",
        "def mseloss(t_p, t_c):\n",
        "  squared_diffs = (t_p - t_c) ** 2\n",
        "  return squared_diffs.mean();"
      ],
      "metadata": {
        "id": "JpJ5f_4SOJFF"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5 Inputs\n",
        "epochs = 5000 #100000\n",
        "lr = 0.001 #  lr = 0.1, # lr = 0.01, # lr = 0.0001,\n",
        "params = torch.tensor([0.0, 1.0, 1.0, 1.0, 1.0, 1.0], requires_grad=True)\n",
        "\n",
        "\n",
        "#optimizer = optim.SGD([params], lr=lr)\n",
        "optimizer = optim.Adam([params], lr=lr)\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "  if params.grad is not None:\n",
        "    params.grad.zero_()\n",
        "\n",
        "  t_p = partialmodel(partialtrainexplanatory, *params)\n",
        "  loss = mseloss(t_p, traintruth)\n",
        "  t_v = partialmodel(partialtestexplanatory, *params)\n",
        "  valloss = mseloss(t_v, testtruth)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    params -= lr * params.grad\n",
        "\n",
        "  if epoch % 500 == 0:\n",
        "    print('Epoch %d, Loss %f, Validation Loss %f' % (epoch, float(loss), float(valloss)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu3OysDcN8wL",
        "outputId": "7426f7fe-570f-412e-ad31-890dbc4380c3"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 6018205745742.316406, Validation Loss 5410330584617.195312\n",
            "Epoch 1000, Loss 3444604505890.724609, Validation Loss 3180612894052.271484\n",
            "Epoch 1500, Loss 3072193026913.602051, Validation Loss 2939480973457.093262\n",
            "Epoch 2000, Loss 3018299780136.859375, Validation Loss 2935531045533.281250\n",
            "Epoch 2500, Loss 3010500428527.332520, Validation Loss 2946731265375.321289\n",
            "Epoch 3000, Loss 3009371799620.195312, Validation Loss 2952830325818.605957\n",
            "Epoch 3500, Loss 3009208493021.770508, Validation Loss 2955416316937.838379\n",
            "Epoch 4000, Loss 3009184873489.636230, Validation Loss 2956437656709.596191\n",
            "Epoch 4500, Loss 3009181454701.430664, Validation Loss 2956830522146.016602\n",
            "Epoch 5000, Loss 3009180959016.550293, Validation Loss 2956978086424.639160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5 Inputs\n",
        "epochs = 5000 #100000\n",
        "lr = 0.001 #  lr = 0.0001, # lr = 0.1, # lr = 0.01,\n",
        "params = torch.tensor([0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], requires_grad=True)\n",
        "\n",
        "\n",
        "#optimizer = optim.SGD([params], lr=lr)\n",
        "optimizer = optim.Adam([params], lr=lr)\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "  if params.grad is not None:\n",
        "    params.grad.zero_()\n",
        "\n",
        "  t_p = fullmodel(fulltrainexplanatory, *params)\n",
        "  loss = mseloss(t_p, traintruth)\n",
        "  t_v = fullmodel(fulltestexplanatory, *params)\n",
        "  valloss = mseloss(t_v, testtruth)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    params -= lr * params.grad\n",
        "\n",
        "  if epoch % 500 == 0:\n",
        "    print('Epoch %d, Loss %f, Validation Loss %f' % (epoch, float(loss), float(valloss)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rADZ9hc0ROt7",
        "outputId": "9257646d-69fa-433a-8fb1-c83fd2c1d885"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 6262994992080.244141, Validation Loss 5659523391881.043945\n",
            "Epoch 1000, Loss 3678746474151.362305, Validation Loss 3425563450587.689453\n",
            "Epoch 1500, Loss 3247658613606.986328, Validation Loss 3135899212735.298828\n",
            "Epoch 2000, Loss 3175746320164.909180, Validation Loss 3121469881686.574219\n",
            "Epoch 2500, Loss 3163749735938.838379, Validation Loss 3132905420597.503418\n",
            "Epoch 3000, Loss 3161748608868.707520, Validation Loss 3140466469381.775391\n",
            "Epoch 3500, Loss 3161414753261.788086, Validation Loss 3144037080527.580078\n",
            "Epoch 4000, Loss 3161359049850.500977, Validation Loss 3145576332533.517578\n",
            "Epoch 4500, Loss 3161349778990.086426, Validation Loss 3146216621395.637695\n",
            "Epoch 5000, Loss 3161348230571.668945, Validation Loss 3146478851412.097656\n"
          ]
        }
      ]
    }
  ]
}